files
for (i in seq_along(paths)) {
files [[i]] <- read_csv(paths[[i]])
}
files
paths
paths <- dir("data", pattern = "student.*.csv", full.names = TRUE)
paths
length(paths)
files <- vector("list", length = length(paths))
files
a <- vector("integer", length = 2)
a
seq_along(paths)
for (i in seq_along(paths)) {
files [[i]] <- read_csv(paths[[i]])
}
files
do.call(rbind, files)
for (path in paths) {
out <- rbind(out, readxl::read_excel(path))
}
out <- NULL
for (path in paths) {
out <- rbind(out, readxl::read_excel(path))
}
# plots ----
hist(diamonds$carat)
plot(diamonds$carat, diamonds$price)
x = as.data.frame(rnorm(50, 50, 10))
x = as.data.frame(rnorm(50, 50, 10))
x = as.data.frame(rnorm(50, 50, 10))
x
View(x)
ggplot2::ggplot(x,aes(x = x)) + geom_dotplot()
library(tidyverse)
ggplot(x,aes(x = x)) + geom_dotplot()
x = as.data.frame(rnorm(50,50,10))
ggplot(x, aes(x = x)) + geom_dotplot()
x = rnorm(50,50,10)
ggplot(x, aes(x = x)) + geom_dotplot()
x
x = as.data.frame(rnorm(50,50,10))
ggplot(x, aes(x = x)) + geom_dotplot()
rlang::last_trace()
x = as.data.frame(a = rnorm(50,50,10))
x = data.frame(rnorm(50,50,10))
ggplot(x, aes(x = x)) + geom_dotplot()
x
x = data.frame(a = rnorm(50,50,10))
x
ggplot(x, aes(x = a)) + geom_dotplot()
x = as.data.frame(a = rnorm(50,50,10))
x = as.data.frame(data.frame(a= rnorm(50, 50, 10)))
ggplot(x,aes(x = a)) + geom_dotplot()
# ChatGPT----
set.seed(123)
n <- 100
x <- rnorm(n)
x
rnorm(n)
set.seed(123)
rnorm(n)
epsilon <- rnorm(n, mean=0, sd = 2)
beta0 <- 1
beta1 <- 2
y <- beta0 + beta1 * x + epsilon
y
likelihood <- function(params) {
beta0 <- params[1]
beta1 <- params[2]
sigma <- params[3]
log_likelihood <- -(n/2) * log(2 * pi * sigma^2) - (1/(2 * sigma^2)) * sum((y - beta0 - beta1 * x)^2)
return(-log_likelihood)  # 返回对数似然函数的相反数，因为optim函数默认进行最小化
}
# 最大似然估计
initial_params <- c(0, 0, 1)  # 初始参数值
result <- optim(initial_params, likelihood, method = "BFGS")  # 使用BFGS算法进行优化
estimated_params <- result$par  # 估计的参数值
sigma_hat <- sqrt(1 / estimated_params[3])  # 估计的标准差
# 打印结果
cat("真实参数：beta0 =", beta0, "beta1 =", beta1, "\n")
cat("估计参数：beta0_hat =", estimated_params[1], "beta1_hat =", estimated_params[2], "\n")
cat("估计的标准差：sigma_hat =", sigma_hat, "\n")
#计算残差
residuals <- y - estimated_params[1] - estimated_params[2] * x
# 绘制残差图
plot(x, residuals, xlab = "x", ylab = "Residuals", main = "Residual Plot")
# 绘制QQ图
qqnorm(residuals)
qqline(residuals)
# 进行假设检验
shapiro.test(residuals)
# ChatGPT----
set.seed(123)
n <- 1000
x <- rnorm(n)
epsilon <- rnorm(n, mean=0, sd = 2)
beta0 <- 1
beta1 <- 2
y <- beta0 + beta1 * x + epsilon
likelihood <- function(params) {
beta0 <- params[1]
beta1 <- params[2]
sigma <- params[3]
log_likelihood <- -(n/2) * log(2 * pi * sigma^2) - (1/(2 * sigma^2)) * sum((y - beta0 - beta1 * x)^2)
return(-log_likelihood)  # 返回对数似然函数的相反数，因为optim函数默认进行最小化
}
# 最大似然估计
initial_params <- c(0, 0, 1)  # 初始参数值
result <- optim(initial_params, likelihood, method = "BFGS")  # 使用BFGS算法进行优化
estimated_params <- result$par  # 估计的参数值
sigma_hat <- sqrt(1 / estimated_params[3])  # 估计的标准差
# 打印结果
cat("真实参数：beta0 =", beta0, "beta1 =", beta1, "\n")
cat("估计参数：beta0_hat =", estimated_params[1], "beta1_hat =", estimated_params[2], "\n")
cat("估计的标准差：sigma_hat =", sigma_hat, "\n")
# ChatGPT----
set.seed(123)
n <- 1000
x <- rnorm(n)
epsilon <- rnorm(n, mean=0, sd = 2)
beta0 <- 1
beta1 <- 2
y <- beta0 + beta1 * x + epsilon
likelihood <- function(params) {
beta0 <- params[1]
beta1 <- params[2]
sigma <- params[3]
log_likelihood <- -(n/2) * log(2 * pi * sigma^2) - (1/(2 * sigma^2)) * sum((y - beta0 - beta1 * x)^2)
return(-log_likelihood)  # 返回对数似然函数的相反数，因为optim函数默认进行最小化
}
# 最大似然估计
initial_params <- c(0, 0, 1)  # 初始参数值
result <- optim(initial_params, likelihood, method = "BFGS")  # 使用BFGS算法进行优化
estimated_params <- result$par  # 估计的参数值
sigma_hat <- sqrt(1 / estimated_params[3])  # 估计的标准差
# 打印结果
cat("真实参数：beta0 =", beta0, "beta1 =", beta1, "\n")
cat("估计参数：beta0_hat =", estimated_params[1], "beta1_hat =", estimated_params[2], "\n")
cat("估计的标准差：sigma_hat =", sigma_hat, "\n")
n <- 1000
x <- rnorm(n)
epsilon <- rnorm(n, mean=0, sd = 1)
beta0 <- 1
beta1 <- 2
y <- beta0 + beta1 * x + epsilon
likelihood <- function(params) {
beta0 <- params[1]
beta1 <- params[2]
sigma <- params[3]
log_likelihood <- -(n/2) * log(2 * pi * sigma^2) - (1/(2 * sigma^2)) * sum((y - beta0 - beta1 * x)^2)
return(-log_likelihood)  # 返回对数似然函数的相反数，因为optim函数默认进行最小化
}
# 最大似然估计
initial_params <- c(0, 0, 1)  # 初始参数值
result <- optim(initial_params, likelihood, method = "BFGS")  # 使用BFGS算法进行优化
estimated_params <- result$par  # 估计的参数值
sigma_hat <- sqrt(1 / estimated_params[3])  # 估计的标准差
# 打印结果
cat("真实参数：beta0 =", beta0, "beta1 =", beta1, "\n")
cat("估计参数：beta0_hat =", estimated_params[1], "beta1_hat =", estimated_params[2], "\n")
cat("估计的标准差：sigma_hat =", sigma_hat, "\n")
#计算残差
residuals <- y - estimated_params[1] - estimated_params[2] * x
# 绘制残差图
plot(x, residuals, xlab = "x", ylab = "Residuals", main = "Residual Plot")
# 绘制QQ图
qqnorm(residuals)
qqline(residuals)
# 进行假设检验
shapiro.test(residuals)
# 计算协方差矩阵
hessian <- numDeriv::hessian(likelihood, estimated_params)
cov_matrix <- solve(hessian)
# 提取参数的标准差
std_errors <- sqrt(diag(cov_matrix))
# 打印参数估计和标准差
cat("Parameter Estimates:\n")
cat("beta0:", estimated_params[1], "\n")
cat("beta1:", estimated_params[2], "\n")
cat("sigma:", estimated_params[3], "\n")
cat("\nStandard Errors:\n")
cat("beta0:", std_errors[1], "\n")
cat("beta1:", std_errors[2], "\n")
cat("sigma:", std_errors[3], "\n")
cov_matrix
# 提取参数的标准差
std_errors <- sqrt(diag(cov_matrix))
# 提取参数间的协方差
cov_beta0_beta1 <- cov_matrix[1, 2]
cov_beta0_sigma <- cov_matrix[1, 3]
cov_beta1_sigma <- cov_matrix[2, 3]
# 打印参数估计和标准差
cat("Parameter Estimates:\n")
cat("beta0:", estimated_params[1], "\n")
cat("beta1:", estimated_params[2], "\n")
cat("sigma:", estimated_params[3], "\n")
cat("\nStandard Errors:\n")
cat("beta0:", std_errors[1], "\n")
cat("beta1:", std_errors[2], "\n")
cat("sigma:", std_errors[3], "\n")
cat("\nCovariances:\n")
cat("Cov(beta0, beta1):", cov_beta0_beta1, "\n")
cat("Cov(beta0, sigma):", cov_beta0_sigma, "\n")
cat("Cov(beta1, sigma):", cov_beta1_sigma, "\n")
library(tidyverse)
library(palmerpenguins)
library(ggthemes)
ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
geom_point()
ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
geom_point();
penguins |> ggplot(aes(x= flipper_length_mm, y = body_mass_g)) +
geom_line()
styler:::style_active_file()
penguins
glimpse(penguins)
View(penguins)
ggplot(data = penguins)
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
)
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
) +
geom_point()
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)
) +
geom_point()
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)
) +
geom_point() +
geom_smooth(method = "lm")
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
) +
geom_point(aes(color = species)) +
geom_smooth(method = "lm")
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
) +
geom_point(aes(color = species, shape = species)) +
geom_smooth(method = "lm") +
labs(
title = "Body mass and flipper length",
subtitle = "Dimensions for Adelie, Chinstrap, and Gentoo penguins",
x = "Flipper length (mm)",
y = "Body mass (g)",
color = "Species"
)
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
) +
geom_point(aes(color = species, shape = species)) +
geom_smooth(method = "lm") +
labs(
title = "Body mass and flipper length",
subtitle = "Dimensions for Adelie, Chinstrap, and Gentoo penguins",
x = "Flipper length (mm)",
y = "Body mass (g)",
color = "Species",
shape = "Species"
) +
scale_color_colorblind()
#---------
# pipe using
ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
geom_point()
penguins %>% ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +
geom_point()
penguins |> ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +
geom_point()
penguins %>% ggplot(aes(
x = penguins$flipper_length_mm,
y = penguins$body_mass_g
)) +
geom_point()
ggplot(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
) +
geom_point() +
geom_smooth()
ggplot() +
geom_point(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
) +
geom_smooth(
data = penguins,
mapping = aes(x = flipper_length_mm, y = body_mass_g)
)
# 1.4 Visualizing distributions
ggplot(penguins, aes(x = species)) +
geom_bar()
1/200*300
(1+2)/3
(1+2)/9
sin(pi/2)
primes <- c(2,3,4,7)
x <- 3*4
primes <- c(2,3,4,7)
primes
primes*2
primes-1
seq(from=1,to=10)
seq(from=1,to=10)
seq(1,10)
x<- "hello world"
x
# install.packages("nycflights13")
library(nycflights13)
library(tidyverse)
# stats::filter()和stats::lag()，这是R包中的基本函数，与dplyr::filter()等冲突
nycflights13::flights
flights
View(flights)
glimpse(flights)
print(flights, width = Inf)
print(flights, width = 3)
print(flights, width = 4)
print(flights)
print(flights, width = Inf)
print(flights, width = 10)
print(flights, width = [1:3])
print(flights, width = 1:3)
print(flights, width = 3)
print(flights, width = Inf)
[1:3]
1:3
print(flights, width = (1:3))
print(flights, width = 2)
print(flights, width = 8)
print(flights, width = 12)
print(flights, width = 20)
# rows
flights %>%
filter(dep_delay > 120)
flights %>%
filter(month == 1 & day == 1)
flights %>%
filter(month == 1, day == 1)
flights %>%
filter(month == 1 | month == 2)
# rows
flights %>%
filter(dep_delay > 120)
flights %>%
filter(month == 1 & day == 1)
print(flights, width = c(1:3))
# rows
flights %>%
filter(dep_delay > 120)
flights %>%
filter(month == 1 & day == 1)
flights %>%
filter(month == 1, day == 1)
flights %>%
filter(month == 1 | month == 2)
# A shorter way to select flights that departed in January or February
flights %>%
filter(month %in% c(1, 2))
jan1 <- flights %>%
filter(month == 1 & day == 1)
jan1
flights |>
filter(month == 1 | 2) # this "works",but not wanted
flights %>%
arrange(dep_time)
flights %>%
arrange(month, dep_time)
flights %>%
arrange(month, day, dep_time) # day1.1 dep_time ordered
jan1
flights |>
arrange(month,day, desc(dep_time))
dep_time_arranged <- flights %>%
arrange(month, day, dep_time)
View(dep_time_arranged)
flights %>%
arrange(desc(dep_delay))
flights %>%
distinct()
View(flights)
flights
flights %>%
distinct()
# find the first occurrence of a unique row in the dataset and discard the rest.
flights %>%
distinct(origin, dest)
# find the first occurrence of a unique row in the dataset and discard the rest.
flights %>%
distinct(origin, dest) |>
arrange(origin)
# find the first occurrence of a unique row in the dataset and discard the rest.
flights %>%
distinct(origin, dest) |>
arrange(origin,dest)
flights %>%
distinct(origin, dest, .keep_all = TRUE)
flights
flights %>%
count(origin, dest, sort = TRUE)
flights %>%
count(origin, dest, sort = TRUE, .keep_all = TRUE)
flights %>%
count(origin, dest)
flights %>%
count(origin, dest, .drop = FALSE)
# columns
mutate_test <- flights %>%
mutate(
gain = dep_delay - arr_delay,
speed = distance / air_time * 60
)
glimpse(mutate_test)
flights %>%
mutate(
gain = dep_delay - arr_delay,
speed = distance / air_time * 60,
.before = year
)
flights %>%
mutate(
gain = dep_delay - arr_delay,
speed = distance / air_time * 60,
.after = year
)
flights %>%
mutate(
gain = dep_delay - arr_delay,
speed = distance / air_time * 60,
.keep = "used"
)
flights %>%
select(year)
flights %>%
select(year, month, day)
flights %>%
select(year:day)
flights %>%
select(!year:day)
flights %>%
select(where(is.character))
is.character(flights)
is.character(flights$year)
is.character(flights$carrier)
?select
flights |>
select(c(year,day))
?janitor::clean_names
rename_test <- flights %>%
rename(tail_num = tailnum)
View(rename_test)
flights %>%
relocate(time_hour, air_time)
flights %>%
relocate(time_hour, air_time, .before = month)
flights %>%
relocate(year:dep_time, .after = sched_dep_time)
flights %>%
relocate(starts_with("arr"), .before = dep_time)
# pipe
flights |>
filter(dest == "IAH") |>
mutate(speed = distance / air_time * 60) |>
select(year:day, dep_time, carrier, flight, speed) |>
arrange(desc(speed))
arrange(
select(
mutate(
filter(
flights,
dest == "IAH"
),
speed = distance / air_time * 60
),
year:day, dep_time, carrier, flight, speed
),
desc(speed)
)
# group_by()
flights |>
group_by(month)
flights |>
group_by(month) |>
summarize(
avg_delay = mean(dep_delay)
)
flights |>
group_by(month) |>
summarize(
avg_delay = mean(dep_delay, na.rm = TRUE)
)
flights |>
group_by(month) |>
summarize(
avg_delay = mean(dep_delay, na.rm = TRUE),
n = n()
)
flights |>
group_by(dest)
